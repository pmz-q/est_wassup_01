{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "\n",
    "from models import ANN\n",
    "from model_selection import KFoldCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.read_csv('trn_X.csv', index_col='Id')\n",
    "y_df = pd.read_csv('trn_y.csv', index_col='Id')\n",
    "\n",
    "X, y = torch.tensor(X_df.to_numpy(dtype=np.float32)), torch.tensor(y_df.to_numpy(dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>287</th>\n",
       "      <th>288</th>\n",
       "      <th>289</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.033420</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.949275</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.125089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064212</td>\n",
       "      <td>0.140098</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038795</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.173281</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121575</td>\n",
       "      <td>0.206547</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.046507</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.086109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.185788</td>\n",
       "      <td>0.150573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.038561</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.311594</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.038271</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.231164</td>\n",
       "      <td>0.123732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.060576</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.927536</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.116052</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.209760</td>\n",
       "      <td>0.187398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.030929</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.920290</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.407962</td>\n",
       "      <td>0.155974</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055505</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.768116</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.139972</td>\n",
       "      <td>0.110583</td>\n",
       "      <td>0.252140</td>\n",
       "      <td>0.252373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.036187</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.048724</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375428</td>\n",
       "      <td>0.188543</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039342</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.008682</td>\n",
       "      <td>0.698100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.040370</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.673913</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.147059</td>\n",
       "      <td>0.196744</td>\n",
       "      <td>0.058219</td>\n",
       "      <td>0.205565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1460 rows × 297 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2      3         4         5         6  \\\n",
       "Id                                                                        \n",
       "1     0.235294  0.033420  0.666667  0.500  0.949275  0.883333  0.125089   \n",
       "2     0.000000  0.038795  0.555556  0.875  0.753623  0.433333  0.173281   \n",
       "3     0.235294  0.046507  0.666667  0.500  0.934783  0.866667  0.086109   \n",
       "4     0.294118  0.038561  0.666667  0.500  0.311594  0.333333  0.038271   \n",
       "5     0.235294  0.060576  0.777778  0.500  0.927536  0.833333  0.116052   \n",
       "...        ...       ...       ...    ...       ...       ...       ...   \n",
       "1456  0.235294  0.030929  0.555556  0.500  0.920290  0.833333  0.000000   \n",
       "1457  0.000000  0.055505  0.555556  0.625  0.768116  0.633333  0.139972   \n",
       "1458  0.294118  0.036187  0.666667  1.000  0.500000  0.933333  0.048724   \n",
       "1459  0.000000  0.039342  0.444444  0.625  0.565217  0.766667  0.008682   \n",
       "1460  0.000000  0.040370  0.444444  0.625  0.673913  0.250000  0.147059   \n",
       "\n",
       "             7         8         9  ...  287  288  289  290  291  292  293  \\\n",
       "Id                                  ...                                      \n",
       "1     0.000000  0.064212  0.140098  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "2     0.000000  0.121575  0.206547  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "3     0.000000  0.185788  0.150573  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "4     0.000000  0.231164  0.123732  ...  0.0  0.0  0.0  1.0  1.0  0.0  0.0   \n",
       "5     0.000000  0.209760  0.187398  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "...        ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "1456  0.000000  0.407962  0.155974  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "1457  0.110583  0.252140  0.252373  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "1458  0.000000  0.375428  0.188543  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "1459  0.698100  0.000000  0.176432  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "1460  0.196744  0.058219  0.205565  ...  0.0  0.0  0.0  1.0  0.0  0.0  0.0   \n",
       "\n",
       "      294  295  296  \n",
       "Id                   \n",
       "1     0.0  1.0  0.0  \n",
       "2     0.0  1.0  0.0  \n",
       "3     0.0  1.0  0.0  \n",
       "4     0.0  0.0  0.0  \n",
       "5     0.0  1.0  0.0  \n",
       "...   ...  ...  ...  \n",
       "1456  0.0  1.0  0.0  \n",
       "1457  0.0  1.0  0.0  \n",
       "1458  0.0  1.0  0.0  \n",
       "1459  0.0  1.0  0.0  \n",
       "1460  0.0  1.0  0.0  \n",
       "\n",
       "[1460 rows x 297 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs = {\n",
    "  'input_dim': X.shape[-1],\n",
    "  'hidden_dim': [128, 512, 128],\n",
    "  'drop_ratio': 0.3,\n",
    "}\n",
    "\n",
    "dl_kwargs = {\n",
    "  'batch_size': 36,\n",
    "  'shuffle': True,\n",
    "}\n",
    "\n",
    "optim_kwargs = {\n",
    "  'lr': 1.0,\n",
    "}\n",
    "\n",
    "device = 'cpu'\n",
    "\n",
    "cv = KFoldCV(X, y, ANN, model_kwargs=model_kwargs,\n",
    "            epochs=300,\n",
    "            criterion=F.mse_loss,\n",
    "            Optimizer=torch.optim.Adam,\n",
    "            optim_kwargs=optim_kwargs,\n",
    "            trn_dl_kwargs=dl_kwargs, val_dl_kwargs=dl_kwargs,\n",
    "            metric=torchmetrics.MeanSquaredError(squared=False).to(device),\n",
    "            device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANN(\n",
      "  (Identity): Identity()\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (activation): Sigmoid()\n",
      "  (module_list): ModuleList(\n",
      "    (0): Linear(in_features=297, out_features=128, bias=True)\n",
      "    (1): Identity()\n",
      "    (2): Sigmoid()\n",
      "    (3): Linear(in_features=128, out_features=512, bias=True)\n",
      "    (4): Identity()\n",
      "    (5): Sigmoid()\n",
      "    (6): Linear(in_features=512, out_features=128, bias=True)\n",
      "    (7): Identity()\n",
      "    (8): Sigmoid()\n",
      "    (9): Linear(in_features=128, out_features=1, bias=True)\n",
      "    (10): Identity()\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "836002dc98ee4ae181582c20680ed33e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sdk/miniconda3/envs/MathAI/lib/python3.10/site-packages/torch/autograd/__init__.py:251: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/sdk/Work/estsoft/Task/2023-11-22-housing-price-regression/Evaluate.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/sdk/Work/estsoft/Task/2023-11-22-housing-price-regression/Evaluate.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m res \u001b[39m=\u001b[39m cv()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sdk/Work/estsoft/Task/2023-11-22-housing-price-regression/Evaluate.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m res \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([res, res\u001b[39m.\u001b[39mapply([\u001b[39m'\u001b[39m\u001b[39mmean\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mstd\u001b[39m\u001b[39m'\u001b[39m])])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sdk/Work/estsoft/Task/2023-11-22-housing-price-regression/Evaluate.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m res\n",
      "File \u001b[0;32m~/Work/estsoft/Task/2023-11-22-housing-price-regression/model_selection/kfold.py:69\u001b[0m, in \u001b[0;36mKFoldCV.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 69\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun()\n",
      "File \u001b[0;32m~/Work/estsoft/Task/2023-11-22-housing-price-regression/model_selection/kfold.py:57\u001b[0m, in \u001b[0;36mKFoldCV.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m pbar \u001b[39m=\u001b[39m trange(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mepochs) \u001b[39m#trange Tqdm + range\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m pbar:\n\u001b[0;32m---> 57\u001b[0m   Train()\u001b[39m.\u001b[39;49mtrain_one_epoch(m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcriterion, optim, dl_trn, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmetric, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice)\n\u001b[1;32m     58\u001b[0m   trn_rmse \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetric\u001b[39m.\u001b[39mcompute()\u001b[39m.\u001b[39mitem()\n\u001b[1;32m     59\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetric\u001b[39m.\u001b[39mreset()\n",
      "File \u001b[0;32m~/Work/estsoft/Task/2023-11-22-housing-price-regression/trains/train.py:41\u001b[0m, in \u001b[0;36mTrain.train_one_epoch\u001b[0;34m(self, model, criterion, optimizer, data_loader, metric, device)\u001b[0m\n\u001b[1;32m     39\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     40\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> 41\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     42\u001b[0m metric\u001b[39m.\u001b[39mupdate(output, y)\n",
      "File \u001b[0;32m~/miniconda3/envs/MathAI/lib/python3.10/site-packages/torch/optim/optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    369\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    370\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m             )\n\u001b[0;32m--> 373\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    374\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    376\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/MathAI/lib/python3.10/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     77\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[39m.\u001b[39m_dynamo\u001b[39m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/miniconda3/envs/MathAI/lib/python3.10/site-packages/torch/optim/adam.py:163\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    152\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m'\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    154\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[1;32m    155\u001b[0m         group,\n\u001b[1;32m    156\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    160\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    161\u001b[0m         state_steps)\n\u001b[0;32m--> 163\u001b[0m     adam(\n\u001b[1;32m    164\u001b[0m         params_with_grad,\n\u001b[1;32m    165\u001b[0m         grads,\n\u001b[1;32m    166\u001b[0m         exp_avgs,\n\u001b[1;32m    167\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    168\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    169\u001b[0m         state_steps,\n\u001b[1;32m    170\u001b[0m         amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    171\u001b[0m         beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    172\u001b[0m         beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    173\u001b[0m         lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    174\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    175\u001b[0m         eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    176\u001b[0m         maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    177\u001b[0m         foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    178\u001b[0m         capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    179\u001b[0m         differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    180\u001b[0m         fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    181\u001b[0m         grad_scale\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgrad_scale\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    182\u001b[0m         found_inf\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfound_inf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    183\u001b[0m     )\n\u001b[1;32m    185\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniconda3/envs/MathAI/lib/python3.10/site-packages/torch/optim/adam.py:311\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 311\u001b[0m func(params,\n\u001b[1;32m    312\u001b[0m      grads,\n\u001b[1;32m    313\u001b[0m      exp_avgs,\n\u001b[1;32m    314\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    315\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    316\u001b[0m      state_steps,\n\u001b[1;32m    317\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    318\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    319\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    320\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    321\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    322\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    323\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    324\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    325\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    326\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    327\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
      "File \u001b[0;32m~/miniconda3/envs/MathAI/lib/python3.10/site-packages/torch/optim/adam.py:434\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    432\u001b[0m         denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[0;32m--> 434\u001b[0m     param\u001b[39m.\u001b[39;49maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49mstep_size)\n\u001b[1;32m    436\u001b[0m \u001b[39m# Lastly, switch back to complex view\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[39mif\u001b[39;00m amsgrad \u001b[39mand\u001b[39;00m torch\u001b[39m.\u001b[39mis_complex(params[i]):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "res = cv()\n",
    "res = pd.concat([res, res.apply(['mean', 'std'])])\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
